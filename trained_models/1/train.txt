python train.py --strength 1

/opt/homebrew/Caskroom/miniconda/base/envs/interpret/lib/python2.7/site-packages/autograd/core.py:120: UserWarning:
------------------------------
    defgrad is deprecated!
------------------------------
Use defvjp instead ("define vector-Jacobian product").
The interface is a little different - look at
autograd/numpy/numpy_grads.py for examples.

  warnings.warn(defgrad_deprecated)
training deep net... [1/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 74.29 | apl: 0.00
model: gru | iter: 10 | loss: 55.39 | apl: 0.00
model: gru | iter: 20 | loss: 46.27 | apl: 1.34
building surrogate dataset...
training surrogate net... [1/12]
model: mlp | iter: 0 | loss: 24.21
model: mlp | iter: 250 | loss: 1.63
model: mlp | iter: 500 | loss: 1.00
model: mlp | iter: 750 | loss: 1.00
model: mlp | iter: 1000 | loss: 1.00
model: mlp | iter: 1250 | loss: 1.00
model: mlp | iter: 1500 | loss: 1.00
model: mlp | iter: 1750 | loss: 1.00
model: mlp | iter: 2000 | loss: 1.00
model: mlp | iter: 2250 | loss: 1.00
model: mlp | iter: 2500 | loss: 1.00
model: mlp | iter: 2750 | loss: 1.00
training deep net... [2/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 38.89 | apl: 3.03
model: gru | iter: 10 | loss: 25.33 | apl: 2.43
model: gru | iter: 20 | loss: 13.21 | apl: 2.43
building surrogate dataset...
training surrogate net... [2/12]
model: mlp | iter: 0 | loss: 26.83
model: mlp | iter: 250 | loss: 1.14
model: mlp | iter: 500 | loss: 0.89
model: mlp | iter: 750 | loss: 0.89
model: mlp | iter: 1000 | loss: 0.89
model: mlp | iter: 1250 | loss: 0.89
model: mlp | iter: 1500 | loss: 0.89
model: mlp | iter: 1750 | loss: 0.89
model: mlp | iter: 2000 | loss: 0.89
model: mlp | iter: 2250 | loss: 0.89
model: mlp | iter: 2500 | loss: 0.89
model: mlp | iter: 2750 | loss: 0.89
training deep net... [3/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 10.25 | apl: 2.43
model: gru | iter: 10 | loss: 7.35 | apl: 2.43
model: gru | iter: 20 | loss: 4.68 | apl: 2.43
building surrogate dataset...
training surrogate net... [3/12]
model: mlp | iter: 0 | loss: 26.19
model: mlp | iter: 250 | loss: 0.98
model: mlp | iter: 500 | loss: 0.74
model: mlp | iter: 750 | loss: 0.74
model: mlp | iter: 1000 | loss: 0.74
model: mlp | iter: 1250 | loss: 0.74
model: mlp | iter: 1500 | loss: 0.74
model: mlp | iter: 1750 | loss: 0.74
model: mlp | iter: 2000 | loss: 0.74
model: mlp | iter: 2250 | loss: 0.74
model: mlp | iter: 2500 | loss: 0.74
model: mlp | iter: 2750 | loss: 0.74
training deep net... [4/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 3.76 | apl: 2.43
model: gru | iter: 10 | loss: 3.38 | apl: 2.43
model: gru | iter: 20 | loss: 2.74 | apl: 2.43
building surrogate dataset...
training surrogate net... [4/12]
model: mlp | iter: 0 | loss: 26.31
model: mlp | iter: 250 | loss: 0.89
model: mlp | iter: 500 | loss: 0.72
model: mlp | iter: 750 | loss: 0.72
model: mlp | iter: 1000 | loss: 0.72
model: mlp | iter: 1250 | loss: 0.72
model: mlp | iter: 1500 | loss: 0.72
model: mlp | iter: 1750 | loss: 0.72
model: mlp | iter: 2000 | loss: 0.72
model: mlp | iter: 2250 | loss: 0.72
model: mlp | iter: 2500 | loss: 0.72
model: mlp | iter: 2750 | loss: 0.72
training deep net... [5/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 2.59 | apl: 2.43
model: gru | iter: 10 | loss: 2.39 | apl: 2.43
model: gru | iter: 20 | loss: 2.28 | apl: 2.43
building surrogate dataset...
training surrogate net... [5/12]
model: mlp | iter: 0 | loss: 26.10
model: mlp | iter: 250 | loss: 0.88
model: mlp | iter: 500 | loss: 0.73
model: mlp | iter: 750 | loss: 0.72
model: mlp | iter: 1000 | loss: 0.72
model: mlp | iter: 1250 | loss: 0.72
model: mlp | iter: 1500 | loss: 0.72
model: mlp | iter: 1750 | loss: 0.72
model: mlp | iter: 2000 | loss: 0.72
model: mlp | iter: 2250 | loss: 0.72
model: mlp | iter: 2500 | loss: 0.72
model: mlp | iter: 2750 | loss: 0.72
training deep net... [6/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 2.31 | apl: 2.43
model: gru | iter: 10 | loss: 2.25 | apl: 2.43
model: gru | iter: 20 | loss: 2.23 | apl: 2.43
building surrogate dataset...
training surrogate net... [6/12]
model: mlp | iter: 0 | loss: 26.52
model: mlp | iter: 250 | loss: 1.01
model: mlp | iter: 500 | loss: 0.74
model: mlp | iter: 750 | loss: 0.74
model: mlp | iter: 1000 | loss: 0.74
model: mlp | iter: 1250 | loss: 0.74
model: mlp | iter: 1500 | loss: 0.74
model: mlp | iter: 1750 | loss: 0.74
model: mlp | iter: 2000 | loss: 0.74
model: mlp | iter: 2250 | loss: 0.74
model: mlp | iter: 2500 | loss: 0.74
model: mlp | iter: 2750 | loss: 0.74
training deep net... [7/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 2.32 | apl: 2.43
model: gru | iter: 10 | loss: 2.19 | apl: 2.43
model: gru | iter: 20 | loss: 2.01 | apl: 2.43
building surrogate dataset...
training surrogate net... [7/12]
model: mlp | iter: 0 | loss: 27.59
model: mlp | iter: 250 | loss: 1.24
model: mlp | iter: 500 | loss: 0.78
model: mlp | iter: 750 | loss: 0.78
model: mlp | iter: 1000 | loss: 0.78
model: mlp | iter: 1250 | loss: 0.78
model: mlp | iter: 1500 | loss: 0.78
model: mlp | iter: 1750 | loss: 0.78
model: mlp | iter: 2000 | loss: 0.78
model: mlp | iter: 2250 | loss: 0.78
model: mlp | iter: 2500 | loss: 0.78
model: mlp | iter: 2750 | loss: 0.78
training deep net... [8/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 2.24 | apl: 2.43
model: gru | iter: 10 | loss: 2.57 | apl: 2.43
model: gru | iter: 20 | loss: 2.30 | apl: 2.43
building surrogate dataset...
training surrogate net... [8/12]
model: mlp | iter: 0 | loss: 25.26
model: mlp | iter: 250 | loss: 0.97
model: mlp | iter: 500 | loss: 0.80
model: mlp | iter: 750 | loss: 0.80
model: mlp | iter: 1000 | loss: 0.80
model: mlp | iter: 1250 | loss: 0.80
model: mlp | iter: 1500 | loss: 0.80
model: mlp | iter: 1750 | loss: 0.80
model: mlp | iter: 2000 | loss: 0.80
model: mlp | iter: 2250 | loss: 0.80
model: mlp | iter: 2500 | loss: 0.80
model: mlp | iter: 2750 | loss: 0.80
training deep net... [9/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 2.40 | apl: 2.43
model: gru | iter: 10 | loss: 2.34 | apl: 2.43
model: gru | iter: 20 | loss: 2.27 | apl: 2.43
building surrogate dataset...
training surrogate net... [9/12]
model: mlp | iter: 0 | loss: 25.66
model: mlp | iter: 250 | loss: 0.98
model: mlp | iter: 500 | loss: 0.80
model: mlp | iter: 750 | loss: 0.80
model: mlp | iter: 1000 | loss: 0.80
model: mlp | iter: 1250 | loss: 0.80
model: mlp | iter: 1500 | loss: 0.80
model: mlp | iter: 1750 | loss: 0.80
model: mlp | iter: 2000 | loss: 0.80
model: mlp | iter: 2250 | loss: 0.80
model: mlp | iter: 2500 | loss: 0.80
model: mlp | iter: 2750 | loss: 0.80
training deep net... [10/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 2.31 | apl: 2.43
model: gru | iter: 10 | loss: 2.27 | apl: 2.43
model: gru | iter: 20 | loss: 2.20 | apl: 2.43
building surrogate dataset...
training surrogate net... [10/12]
model: mlp | iter: 0 | loss: 25.28
model: mlp | iter: 250 | loss: 0.97
model: mlp | iter: 500 | loss: 0.81
model: mlp | iter: 750 | loss: 0.81
model: mlp | iter: 1000 | loss: 0.81
model: mlp | iter: 1250 | loss: 0.81
model: mlp | iter: 1500 | loss: 0.81
model: mlp | iter: 1750 | loss: 0.81
model: mlp | iter: 2000 | loss: 0.81
model: mlp | iter: 2250 | loss: 0.81
model: mlp | iter: 2500 | loss: 0.81
model: mlp | iter: 2750 | loss: 0.81
training deep net... [11/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 2.30 | apl: 2.43
model: gru | iter: 10 | loss: 2.25 | apl: 2.43
model: gru | iter: 20 | loss: 2.14 | apl: 2.43
building surrogate dataset...
training surrogate net... [11/12]
model: mlp | iter: 0 | loss: 26.69
model: mlp | iter: 250 | loss: 0.96
model: mlp | iter: 500 | loss: 0.83
model: mlp | iter: 750 | loss: 0.82
model: mlp | iter: 1000 | loss: 0.82
model: mlp | iter: 1250 | loss: 0.82
model: mlp | iter: 1500 | loss: 0.82
model: mlp | iter: 1750 | loss: 0.82
model: mlp | iter: 2000 | loss: 0.82
model: mlp | iter: 2250 | loss: 0.82
model: mlp | iter: 2500 | loss: 0.82
model: mlp | iter: 2750 | loss: 0.82
training deep net... [12/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 2.31 | apl: 2.43
model: gru | iter: 10 | loss: 2.33 | apl: 2.43
model: gru | iter: 20 | loss: 2.33 | apl: 2.43
building surrogate dataset...
training surrogate net... [12/12]
model: mlp | iter: 0 | loss: 25.44
model: mlp | iter: 250 | loss: 0.99
model: mlp | iter: 500 | loss: 0.83
model: mlp | iter: 750 | loss: 0.82
model: mlp | iter: 1000 | loss: 0.82
model: mlp | iter: 1250 | loss: 0.82
model: mlp | iter: 1500 | loss: 0.82
model: mlp | iter: 1750 | loss: 0.82
model: mlp | iter: 2000 | loss: 0.82
model: mlp | iter: 2250 | loss: 0.82
model: mlp | iter: 2500 | loss: 0.82
model: mlp | iter: 2750 | loss: 0.82
saved trained model to ./trained_models
saved final decision tree to ./trained_models
