python train.py --strength 1000.0
/opt/homebrew/Caskroom/miniconda/base/envs/interpret/lib/python2.7/site-packages/autograd/core.py:120: UserWarning:
------------------------------
    defgrad is deprecated!
------------------------------
Use defvjp instead ("define vector-Jacobian product").
The interface is a little different - look at
autograd/numpy/numpy_grads.py for examples.

  warnings.warn(defgrad_deprecated)
training deep net... [1/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 557.21 | apl: 0.00
model: gru | iter: 10 | loss: 153.32 | apl: 0.00
model: gru | iter: 20 | loss: 145.50 | apl: 0.00
building surrogate dataset...
training surrogate net... [1/12]
model: mlp | iter: 0 | loss: 24.46
model: mlp | iter: 250 | loss: 1.85
model: mlp | iter: 500 | loss: 1.26
model: mlp | iter: 750 | loss: 1.26
model: mlp | iter: 1000 | loss: 1.26
model: mlp | iter: 1250 | loss: 1.26
model: mlp | iter: 1500 | loss: 1.25
model: mlp | iter: 1750 | loss: 1.25
model: mlp | iter: 2000 | loss: 1.25
model: mlp | iter: 2250 | loss: 1.25
model: mlp | iter: 2500 | loss: 1.25
model: mlp | iter: 2750 | loss: 1.25
training deep net... [2/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 746.46 | apl: 0.00
model: gru | iter: 10 | loss: 726.60 | apl: 3.03
model: gru | iter: 20 | loss: 708.16 | apl: 2.43
building surrogate dataset...
training surrogate net... [2/12]
model: mlp | iter: 0 | loss: 26.05
model: mlp | iter: 250 | loss: 1.59
model: mlp | iter: 500 | loss: 1.44
model: mlp | iter: 750 | loss: 1.44
model: mlp | iter: 1000 | loss: 1.44
model: mlp | iter: 1250 | loss: 1.44
model: mlp | iter: 1500 | loss: 1.44
model: mlp | iter: 1750 | loss: 1.44
model: mlp | iter: 2000 | loss: 1.44
model: mlp | iter: 2250 | loss: 1.44
model: mlp | iter: 2500 | loss: 1.44
model: mlp | iter: 2750 | loss: 1.44
training deep net... [3/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 2543.16 | apl: 2.43
model: gru | iter: 10 | loss: 1793.76 | apl: 2.43
model: gru | iter: 20 | loss: 893.66 | apl: 2.43
building surrogate dataset...
training surrogate net... [3/12]
model: mlp | iter: 0 | loss: 25.68
model: mlp | iter: 250 | loss: 1.01
model: mlp | iter: 500 | loss: 0.89
model: mlp | iter: 750 | loss: 0.89
model: mlp | iter: 1000 | loss: 0.89
model: mlp | iter: 1250 | loss: 0.89
model: mlp | iter: 1500 | loss: 0.89
model: mlp | iter: 1750 | loss: 0.89
model: mlp | iter: 2000 | loss: 0.89
model: mlp | iter: 2250 | loss: 0.89
model: mlp | iter: 2500 | loss: 0.89
model: mlp | iter: 2750 | loss: 0.89
training deep net... [4/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 1912.24 | apl: 0.00
model: gru | iter: 10 | loss: 1152.97 | apl: 0.00
model: gru | iter: 20 | loss: 569.42 | apl: 0.00
building surrogate dataset...
training surrogate net... [4/12]
model: mlp | iter: 0 | loss: 23.83
model: mlp | iter: 250 | loss: 0.62
model: mlp | iter: 500 | loss: 0.49
model: mlp | iter: 750 | loss: 0.49
model: mlp | iter: 1000 | loss: 0.49
model: mlp | iter: 1250 | loss: 0.49
model: mlp | iter: 1500 | loss: 0.49
model: mlp | iter: 1750 | loss: 0.49
model: mlp | iter: 2000 | loss: 0.48
model: mlp | iter: 2250 | loss: 0.48
model: mlp | iter: 2500 | loss: 0.48
model: mlp | iter: 2750 | loss: 0.48
training deep net... [5/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 743.74 | apl: 0.00
model: gru | iter: 10 | loss: 718.79 | apl: 3.03
model: gru | iter: 20 | loss: 700.94 | apl: 2.43
building surrogate dataset...
training surrogate net... [5/12]
model: mlp | iter: 0 | loss: 25.40
model: mlp | iter: 250 | loss: 1.32
model: mlp | iter: 500 | loss: 1.22
model: mlp | iter: 750 | loss: 1.21
model: mlp | iter: 1000 | loss: 1.21
model: mlp | iter: 1250 | loss: 1.21
model: mlp | iter: 1500 | loss: 1.21
model: mlp | iter: 1750 | loss: 1.21
model: mlp | iter: 2000 | loss: 1.21
model: mlp | iter: 2250 | loss: 1.21
model: mlp | iter: 2500 | loss: 1.21
model: mlp | iter: 2750 | loss: 1.21
training deep net... [6/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 2430.84 | apl: 2.43
model: gru | iter: 10 | loss: 2019.23 | apl: 2.43
model: gru | iter: 20 | loss: 1450.41 | apl: 2.43
building surrogate dataset...
training surrogate net... [6/12]
model: mlp | iter: 0 | loss: 26.77
model: mlp | iter: 250 | loss: 1.06
model: mlp | iter: 500 | loss: 0.88
model: mlp | iter: 750 | loss: 0.87
model: mlp | iter: 1000 | loss: 0.87
model: mlp | iter: 1250 | loss: 0.87
model: mlp | iter: 1500 | loss: 0.87
model: mlp | iter: 1750 | loss: 0.87
model: mlp | iter: 2000 | loss: 0.87
model: mlp | iter: 2250 | loss: 0.87
model: mlp | iter: 2500 | loss: 0.87
model: mlp | iter: 2750 | loss: 0.87
training deep net... [7/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 2272.38 | apl: 3.07
model: gru | iter: 10 | loss: 1559.59 | apl: 0.00
model: gru | iter: 20 | loss: 821.63 | apl: 0.00
building surrogate dataset...
training surrogate net... [7/12]
model: mlp | iter: 0 | loss: 24.36
model: mlp | iter: 250 | loss: 1.44
model: mlp | iter: 500 | loss: 1.33
model: mlp | iter: 750 | loss: 1.11
model: mlp | iter: 1000 | loss: 1.10
model: mlp | iter: 1250 | loss: 1.10
model: mlp | iter: 1500 | loss: 1.10
model: mlp | iter: 1750 | loss: 1.10
model: mlp | iter: 2000 | loss: 1.10
model: mlp | iter: 2250 | loss: 1.10
model: mlp | iter: 2500 | loss: 1.10
model: mlp | iter: 2750 | loss: 1.10
training deep net... [8/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 746.54 | apl: 0.00
model: gru | iter: 10 | loss: 723.69 | apl: 2.43
model: gru | iter: 20 | loss: 704.26 | apl: 2.43
building surrogate dataset...
training surrogate net... [8/12]
model: mlp | iter: 0 | loss: 26.09
model: mlp | iter: 250 | loss: 1.41
model: mlp | iter: 500 | loss: 1.28
model: mlp | iter: 750 | loss: 1.27
model: mlp | iter: 1000 | loss: 1.27
model: mlp | iter: 1250 | loss: 1.27
model: mlp | iter: 1500 | loss: 1.27
model: mlp | iter: 1750 | loss: 1.27
model: mlp | iter: 2000 | loss: 1.27
model: mlp | iter: 2250 | loss: 1.27
model: mlp | iter: 2500 | loss: 1.27
model: mlp | iter: 2750 | loss: 1.27
training deep net... [9/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 2439.23 | apl: 2.43
model: gru | iter: 10 | loss: 1832.66 | apl: 2.43
model: gru | iter: 20 | loss: 1052.96 | apl: 1.57
building surrogate dataset...
training surrogate net... [9/12]
model: mlp | iter: 0 | loss: 25.10
model: mlp | iter: 250 | loss: 0.96
model: mlp | iter: 500 | loss: 0.84
model: mlp | iter: 750 | loss: 0.84
model: mlp | iter: 1000 | loss: 0.84
model: mlp | iter: 1250 | loss: 0.84
model: mlp | iter: 1500 | loss: 0.84
model: mlp | iter: 1750 | loss: 0.84
model: mlp | iter: 2000 | loss: 0.84
model: mlp | iter: 2250 | loss: 0.84
model: mlp | iter: 2500 | loss: 0.84
model: mlp | iter: 2750 | loss: 0.84
training deep net... [10/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 1748.92 | apl: 1.57
model: gru | iter: 10 | loss: 1053.46 | apl: 0.00
model: gru | iter: 20 | loss: 542.23 | apl: 0.00
building surrogate dataset...
training surrogate net... [10/12]
model: mlp | iter: 0 | loss: 23.74
model: mlp | iter: 250 | loss: 0.67
model: mlp | iter: 500 | loss: 0.50
model: mlp | iter: 750 | loss: 0.50
model: mlp | iter: 1000 | loss: 0.50
model: mlp | iter: 1250 | loss: 0.50
model: mlp | iter: 1500 | loss: 0.50
model: mlp | iter: 1750 | loss: 0.50
model: mlp | iter: 2000 | loss: 0.50
model: mlp | iter: 2250 | loss: 0.50
model: mlp | iter: 2500 | loss: 0.50
model: mlp | iter: 2750 | loss: 0.50
training deep net... [11/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 743.82 | apl: 0.00
model: gru | iter: 10 | loss: 720.23 | apl: 3.03
model: gru | iter: 20 | loss: 701.65 | apl: 2.43
building surrogate dataset...
training surrogate net... [11/12]
model: mlp | iter: 0 | loss: 26.66
model: mlp | iter: 250 | loss: 1.38
model: mlp | iter: 500 | loss: 1.28
model: mlp | iter: 750 | loss: 1.28
model: mlp | iter: 1000 | loss: 1.28
model: mlp | iter: 1250 | loss: 1.28
model: mlp | iter: 1500 | loss: 1.28
model: mlp | iter: 1750 | loss: 1.28
model: mlp | iter: 2000 | loss: 1.28
model: mlp | iter: 2250 | loss: 1.28
model: mlp | iter: 2500 | loss: 1.28
model: mlp | iter: 2750 | loss: 1.28
training deep net... [12/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 2448.78 | apl: 2.43
model: gru | iter: 10 | loss: 2011.47 | apl: 2.43
model: gru | iter: 20 | loss: 1412.36 | apl: 2.43
building surrogate dataset...
training surrogate net... [12/12]
model: mlp | iter: 0 | loss: 26.72
model: mlp | iter: 250 | loss: 1.08
model: mlp | iter: 500 | loss: 0.84
model: mlp | iter: 750 | loss: 0.83
model: mlp | iter: 1000 | loss: 0.83
model: mlp | iter: 1250 | loss: 0.83
model: mlp | iter: 1500 | loss: 0.83
model: mlp | iter: 1750 | loss: 0.83
model: mlp | iter: 2000 | loss: 0.83
model: mlp | iter: 2250 | loss: 0.83
model: mlp | iter: 2500 | loss: 0.83
model: mlp | iter: 2750 | loss: 0.83
saved trained model to ./trained_models
saved final decision tree to ./trained_models
