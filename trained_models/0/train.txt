python train.py --strength 0

/opt/homebrew/Caskroom/miniconda/base/envs/interpret/lib/python2.7/site-packages/autograd/core.py:120: UserWarning:
------------------------------
    defgrad is deprecated!
------------------------------
Use defvjp instead ("define vector-Jacobian product").
The interface is a little different - look at
autograd/numpy/numpy_grads.py for examples.

  warnings.warn(defgrad_deprecated)
training deep net... [1/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 73.64 | apl: 0.00
model: gru | iter: 10 | loss: 55.09 | apl: 0.00
model: gru | iter: 20 | loss: 46.04 | apl: 1.34
building surrogate dataset...
training surrogate net... [1/12]
model: mlp | iter: 0 | loss: 24.23
model: mlp | iter: 250 | loss: 1.66
model: mlp | iter: 500 | loss: 1.01
model: mlp | iter: 750 | loss: 1.00
model: mlp | iter: 1000 | loss: 1.00
model: mlp | iter: 1250 | loss: 1.00
model: mlp | iter: 1500 | loss: 1.00
model: mlp | iter: 1750 | loss: 1.00
model: mlp | iter: 2000 | loss: 1.00
model: mlp | iter: 2250 | loss: 1.00
model: mlp | iter: 2500 | loss: 1.00
model: mlp | iter: 2750 | loss: 1.00
training deep net... [2/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 37.91 | apl: 3.06
model: gru | iter: 10 | loss: 22.73 | apl: 2.43
model: gru | iter: 20 | loss: 11.60 | apl: 2.43
building surrogate dataset...
training surrogate net... [2/12]
model: mlp | iter: 0 | loss: 26.83
model: mlp | iter: 250 | loss: 1.16
model: mlp | iter: 500 | loss: 0.90
model: mlp | iter: 750 | loss: 0.90
model: mlp | iter: 1000 | loss: 0.90
model: mlp | iter: 1250 | loss: 0.90
model: mlp | iter: 1500 | loss: 0.90
model: mlp | iter: 1750 | loss: 0.90
model: mlp | iter: 2000 | loss: 0.90
model: mlp | iter: 2250 | loss: 0.90
model: mlp | iter: 2500 | loss: 0.90
model: mlp | iter: 2750 | loss: 0.90
training deep net... [3/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 7.21 | apl: 2.43
model: gru | iter: 10 | loss: 7.52 | apl: 2.43
model: gru | iter: 20 | loss: 5.46 | apl: 2.43
building surrogate dataset...
training surrogate net... [3/12]
model: mlp | iter: 0 | loss: 25.87
model: mlp | iter: 250 | loss: 0.96
model: mlp | iter: 500 | loss: 0.74
model: mlp | iter: 750 | loss: 0.74
model: mlp | iter: 1000 | loss: 0.74
model: mlp | iter: 1250 | loss: 0.74
model: mlp | iter: 1500 | loss: 0.74
model: mlp | iter: 1750 | loss: 0.74
model: mlp | iter: 2000 | loss: 0.74
model: mlp | iter: 2250 | loss: 0.74
model: mlp | iter: 2500 | loss: 0.74
model: mlp | iter: 2750 | loss: 0.74
training deep net... [4/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 4.06 | apl: 2.43
model: gru | iter: 10 | loss: 1.88 | apl: 2.43
model: gru | iter: 20 | loss: 0.58 | apl: 2.43
building surrogate dataset...
training surrogate net... [4/12]
model: mlp | iter: 0 | loss: 26.47
model: mlp | iter: 250 | loss: 1.00
model: mlp | iter: 500 | loss: 0.70
model: mlp | iter: 750 | loss: 0.70
model: mlp | iter: 1000 | loss: 0.70
model: mlp | iter: 1250 | loss: 0.70
model: mlp | iter: 1500 | loss: 0.70
model: mlp | iter: 1750 | loss: 0.70
model: mlp | iter: 2000 | loss: 0.70
model: mlp | iter: 2250 | loss: 0.70
model: mlp | iter: 2500 | loss: 0.70
model: mlp | iter: 2750 | loss: 0.70
training deep net... [5/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 0.44 | apl: 2.43
model: gru | iter: 10 | loss: 0.15 | apl: 2.43
model: gru | iter: 20 | loss: 0.05 | apl: 2.43
building surrogate dataset...
training surrogate net... [5/12]
model: mlp | iter: 0 | loss: 26.52
model: mlp | iter: 250 | loss: 1.08
model: mlp | iter: 500 | loss: 0.67
model: mlp | iter: 750 | loss: 0.67
model: mlp | iter: 1000 | loss: 0.67
model: mlp | iter: 1250 | loss: 0.67
model: mlp | iter: 1500 | loss: 0.67
model: mlp | iter: 1750 | loss: 0.67
model: mlp | iter: 2000 | loss: 0.67
model: mlp | iter: 2250 | loss: 0.67
model: mlp | iter: 2500 | loss: 0.67
model: mlp | iter: 2750 | loss: 0.67
training deep net... [6/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 0.03 | apl: 2.43
model: gru | iter: 10 | loss: 0.01 | apl: 2.43
model: gru | iter: 20 | loss: 0.00 | apl: 2.43
building surrogate dataset...
training surrogate net... [6/12]
model: mlp | iter: 0 | loss: 26.83
model: mlp | iter: 250 | loss: 1.24
model: mlp | iter: 500 | loss: 0.65
model: mlp | iter: 750 | loss: 0.65
model: mlp | iter: 1000 | loss: 0.65
model: mlp | iter: 1250 | loss: 0.65
model: mlp | iter: 1500 | loss: 0.65
model: mlp | iter: 1750 | loss: 0.65
model: mlp | iter: 2000 | loss: 0.65
model: mlp | iter: 2250 | loss: 0.65
model: mlp | iter: 2500 | loss: 0.65
model: mlp | iter: 2750 | loss: 0.65
training deep net... [7/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 0.00 | apl: 2.43
model: gru | iter: 10 | loss: 0.00 | apl: 2.43
model: gru | iter: 20 | loss: 0.00 | apl: 2.43
building surrogate dataset...
training surrogate net... [7/12]
model: mlp | iter: 0 | loss: 27.85
model: mlp | iter: 250 | loss: 1.53
model: mlp | iter: 500 | loss: 0.64
model: mlp | iter: 750 | loss: 0.63
model: mlp | iter: 1000 | loss: 0.63
model: mlp | iter: 1250 | loss: 0.63
model: mlp | iter: 1500 | loss: 0.63
model: mlp | iter: 1750 | loss: 0.63
model: mlp | iter: 2000 | loss: 0.63
model: mlp | iter: 2250 | loss: 0.63
model: mlp | iter: 2500 | loss: 0.63
model: mlp | iter: 2750 | loss: 0.63
training deep net... [8/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 0.00 | apl: 2.43
model: gru | iter: 10 | loss: 0.00 | apl: 2.43
model: gru | iter: 20 | loss: 0.00 | apl: 2.43
building surrogate dataset...
training surrogate net... [8/12]
model: mlp | iter: 0 | loss: 25.00
model: mlp | iter: 250 | loss: 0.99
model: mlp | iter: 500 | loss: 0.63
model: mlp | iter: 750 | loss: 0.63
model: mlp | iter: 1000 | loss: 0.63
model: mlp | iter: 1250 | loss: 0.63
model: mlp | iter: 1500 | loss: 0.63
model: mlp | iter: 1750 | loss: 0.63
model: mlp | iter: 2000 | loss: 0.63
model: mlp | iter: 2250 | loss: 0.63
model: mlp | iter: 2500 | loss: 0.63
model: mlp | iter: 2750 | loss: 0.63
training deep net... [9/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 0.00 | apl: 2.43
model: gru | iter: 10 | loss: 0.00 | apl: 2.43
model: gru | iter: 20 | loss: 0.00 | apl: 2.43
building surrogate dataset...
training surrogate net... [9/12]
model: mlp | iter: 0 | loss: 26.48
model: mlp | iter: 250 | loss: 1.49
model: mlp | iter: 500 | loss: 0.62
model: mlp | iter: 750 | loss: 0.62
model: mlp | iter: 1000 | loss: 0.62
model: mlp | iter: 1250 | loss: 0.62
model: mlp | iter: 1500 | loss: 0.62
model: mlp | iter: 1750 | loss: 0.62
model: mlp | iter: 2000 | loss: 0.62
model: mlp | iter: 2250 | loss: 0.62
model: mlp | iter: 2500 | loss: 0.62
model: mlp | iter: 2750 | loss: 0.62
training deep net... [10/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 0.00 | apl: 2.43
model: gru | iter: 10 | loss: 0.00 | apl: 2.43
model: gru | iter: 20 | loss: 0.00 | apl: 2.43
building surrogate dataset...
training surrogate net... [10/12]
model: mlp | iter: 0 | loss: 25.39
model: mlp | iter: 250 | loss: 1.15
model: mlp | iter: 500 | loss: 0.61
model: mlp | iter: 750 | loss: 0.61
model: mlp | iter: 1000 | loss: 0.61
model: mlp | iter: 1250 | loss: 0.61
model: mlp | iter: 1500 | loss: 0.61
model: mlp | iter: 1750 | loss: 0.61
model: mlp | iter: 2000 | loss: 0.61
model: mlp | iter: 2250 | loss: 0.61
model: mlp | iter: 2500 | loss: 0.61
model: mlp | iter: 2750 | loss: 0.61
training deep net... [11/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 0.00 | apl: 2.43
model: gru | iter: 10 | loss: 0.00 | apl: 2.43
model: gru | iter: 20 | loss: 0.00 | apl: 2.43
building surrogate dataset...
training surrogate net... [11/12]
model: mlp | iter: 0 | loss: 26.64
model: mlp | iter: 250 | loss: 1.02
model: mlp | iter: 500 | loss: 0.61
model: mlp | iter: 750 | loss: 0.61
model: mlp | iter: 1000 | loss: 0.61
model: mlp | iter: 1250 | loss: 0.61
model: mlp | iter: 1500 | loss: 0.61
model: mlp | iter: 1750 | loss: 0.61
model: mlp | iter: 2000 | loss: 0.61
model: mlp | iter: 2250 | loss: 0.61
model: mlp | iter: 2500 | loss: 0.61
model: mlp | iter: 2750 | loss: 0.61
training deep net... [12/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 0.00 | apl: 2.43
model: gru | iter: 10 | loss: 0.00 | apl: 2.43
model: gru | iter: 20 | loss: 0.00 | apl: 2.43
building surrogate dataset...
training surrogate net... [12/12]
model: mlp | iter: 0 | loss: 25.26
model: mlp | iter: 250 | loss: 0.86
model: mlp | iter: 500 | loss: 0.62
model: mlp | iter: 750 | loss: 0.61
model: mlp | iter: 1000 | loss: 0.61
model: mlp | iter: 1250 | loss: 0.61
model: mlp | iter: 1500 | loss: 0.61
model: mlp | iter: 1750 | loss: 0.61
model: mlp | iter: 2000 | loss: 0.61
model: mlp | iter: 2250 | loss: 0.61
model: mlp | iter: 2500 | loss: 0.61
model: mlp | iter: 2750 | loss: 0.61
saved trained model to ./trained_models
saved final decision tree to ./trained_models
