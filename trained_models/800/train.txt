python train.py --strength 8
00.0
/opt/homebrew/Caskroom/miniconda/base/envs/interpret/lib/python2.7/site-packages/autograd/core.py:120: UserWarning:
------------------------------
    defgrad is deprecated!
------------------------------
Use defvjp instead ("define vector-Jacobian product").
The interface is a little different - look at
autograd/numpy/numpy_grads.py for examples.

  warnings.warn(defgrad_deprecated)
training deep net... [1/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 724.79 | apl: 0.00
model: gru | iter: 10 | loss: 202.00 | apl: 0.00
model: gru | iter: 20 | loss: 192.67 | apl: 0.00
building surrogate dataset...
training surrogate net... [1/12]
model: mlp | iter: 0 | loss: 24.39
model: mlp | iter: 250 | loss: 1.70
model: mlp | iter: 500 | loss: 1.16
model: mlp | iter: 750 | loss: 1.16
model: mlp | iter: 1000 | loss: 1.16
model: mlp | iter: 1250 | loss: 1.16
model: mlp | iter: 1500 | loss: 1.16
model: mlp | iter: 1750 | loss: 1.16
model: mlp | iter: 2000 | loss: 1.16
model: mlp | iter: 2250 | loss: 1.16
model: mlp | iter: 2500 | loss: 1.16
model: mlp | iter: 2750 | loss: 1.16
training deep net... [2/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 609.69 | apl: 0.00
model: gru | iter: 10 | loss: 589.00 | apl: 3.03
model: gru | iter: 20 | loss: 568.01 | apl: 2.43
building surrogate dataset...
training surrogate net... [2/12]
model: mlp | iter: 0 | loss: 26.82
model: mlp | iter: 250 | loss: 1.60
model: mlp | iter: 500 | loss: 1.38
model: mlp | iter: 750 | loss: 1.38
model: mlp | iter: 1000 | loss: 1.38
model: mlp | iter: 1250 | loss: 1.38
model: mlp | iter: 1500 | loss: 1.38
model: mlp | iter: 1750 | loss: 1.38
model: mlp | iter: 2000 | loss: 1.38
model: mlp | iter: 2250 | loss: 1.38
model: mlp | iter: 2500 | loss: 1.38
model: mlp | iter: 2750 | loss: 1.38
training deep net... [3/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 2067.12 | apl: 2.43
model: gru | iter: 10 | loss: 1536.43 | apl: 2.43
model: gru | iter: 20 | loss: 850.00 | apl: 2.43
building surrogate dataset...
training surrogate net... [3/12]
model: mlp | iter: 0 | loss: 26.09
model: mlp | iter: 250 | loss: 1.02
model: mlp | iter: 500 | loss: 0.88
model: mlp | iter: 750 | loss: 0.88
model: mlp | iter: 1000 | loss: 0.88
model: mlp | iter: 1250 | loss: 0.88
model: mlp | iter: 1500 | loss: 0.88
model: mlp | iter: 1750 | loss: 0.88
model: mlp | iter: 2000 | loss: 0.88
model: mlp | iter: 2250 | loss: 0.88
model: mlp | iter: 2500 | loss: 0.88
model: mlp | iter: 2750 | loss: 0.88
training deep net... [4/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 1811.51 | apl: 2.43
model: gru | iter: 10 | loss: 1148.68 | apl: 0.00
model: gru | iter: 20 | loss: 552.38 | apl: 0.00
building surrogate dataset...
training surrogate net... [4/12]
model: mlp | iter: 0 | loss: 24.24
model: mlp | iter: 250 | loss: 1.32
model: mlp | iter: 500 | loss: 1.23
model: mlp | iter: 750 | loss: 1.01
model: mlp | iter: 1000 | loss: 1.01
model: mlp | iter: 1250 | loss: 1.01
model: mlp | iter: 1500 | loss: 1.01
model: mlp | iter: 1750 | loss: 1.01
model: mlp | iter: 2000 | loss: 1.01
model: mlp | iter: 2250 | loss: 1.01
model: mlp | iter: 2500 | loss: 1.01
model: mlp | iter: 2750 | loss: 1.00
training deep net... [5/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 610.43 | apl: 0.00
model: gru | iter: 10 | loss: 591.77 | apl: 3.03
model: gru | iter: 20 | loss: 572.23 | apl: 2.43
building surrogate dataset...
training surrogate net... [5/12]
model: mlp | iter: 0 | loss: 25.91
model: mlp | iter: 250 | loss: 1.58
model: mlp | iter: 500 | loss: 1.48
model: mlp | iter: 750 | loss: 1.48
model: mlp | iter: 1000 | loss: 1.48
model: mlp | iter: 1250 | loss: 1.48
model: mlp | iter: 1500 | loss: 1.48
model: mlp | iter: 1750 | loss: 1.48
model: mlp | iter: 2000 | loss: 1.48
model: mlp | iter: 2250 | loss: 1.48
model: mlp | iter: 2500 | loss: 1.48
model: mlp | iter: 2750 | loss: 1.48
training deep net... [6/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 2047.52 | apl: 2.43
model: gru | iter: 10 | loss: 1219.63 | apl: 2.43
model: gru | iter: 20 | loss: 446.77 | apl: 0.00
building surrogate dataset...
training surrogate net... [6/12]
model: mlp | iter: 0 | loss: 25.13
model: mlp | iter: 250 | loss: 1.36
model: mlp | iter: 500 | loss: 1.28
model: mlp | iter: 750 | loss: 1.28
model: mlp | iter: 1000 | loss: 1.28
model: mlp | iter: 1250 | loss: 1.28
model: mlp | iter: 1500 | loss: 1.28
model: mlp | iter: 1750 | loss: 1.28
model: mlp | iter: 2000 | loss: 1.28
model: mlp | iter: 2250 | loss: 1.28
model: mlp | iter: 2500 | loss: 1.28
model: mlp | iter: 2750 | loss: 1.28
training deep net... [7/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 338.37 | apl: 0.00
model: gru | iter: 10 | loss: 153.76 | apl: 0.00
model: gru | iter: 20 | loss: 110.44 | apl: 0.00
building surrogate dataset...
training surrogate net... [7/12]
model: mlp | iter: 0 | loss: 24.24
model: mlp | iter: 250 | loss: 0.66
model: mlp | iter: 500 | loss: 0.48
model: mlp | iter: 750 | loss: 0.47
model: mlp | iter: 1000 | loss: 0.47
model: mlp | iter: 1250 | loss: 0.47
model: mlp | iter: 1500 | loss: 0.47
model: mlp | iter: 1750 | loss: 0.47
model: mlp | iter: 2000 | loss: 0.47
model: mlp | iter: 2250 | loss: 0.47
model: mlp | iter: 2500 | loss: 0.47
model: mlp | iter: 2750 | loss: 0.47
training deep net... [8/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 598.17 | apl: 1.34
model: gru | iter: 10 | loss: 575.71 | apl: 2.43
model: gru | iter: 20 | loss: 561.61 | apl: 2.43
building surrogate dataset...
training surrogate net... [8/12]
model: mlp | iter: 0 | loss: 25.20
model: mlp | iter: 250 | loss: 0.90
model: mlp | iter: 500 | loss: 0.67
model: mlp | iter: 750 | loss: 0.67
model: mlp | iter: 1000 | loss: 0.67
model: mlp | iter: 1250 | loss: 0.67
model: mlp | iter: 1500 | loss: 0.67
model: mlp | iter: 1750 | loss: 0.67
model: mlp | iter: 2000 | loss: 0.67
model: mlp | iter: 2250 | loss: 0.67
model: mlp | iter: 2500 | loss: 0.67
model: mlp | iter: 2750 | loss: 0.67
training deep net... [9/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 1869.14 | apl: 2.43
model: gru | iter: 10 | loss: 1696.80 | apl: 2.43
model: gru | iter: 20 | loss: 1441.71 | apl: 2.43
building surrogate dataset...
training surrogate net... [9/12]
model: mlp | iter: 0 | loss: 26.26
model: mlp | iter: 250 | loss: 1.00
model: mlp | iter: 500 | loss: 0.71
model: mlp | iter: 750 | loss: 0.70
model: mlp | iter: 1000 | loss: 0.70
model: mlp | iter: 1250 | loss: 0.70
model: mlp | iter: 1500 | loss: 0.70
model: mlp | iter: 1750 | loss: 0.70
model: mlp | iter: 2000 | loss: 0.70
model: mlp | iter: 2250 | loss: 0.70
model: mlp | iter: 2500 | loss: 0.70
model: mlp | iter: 2750 | loss: 0.70
training deep net... [10/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 1651.06 | apl: 2.43
model: gru | iter: 10 | loss: 1346.89 | apl: 2.43
model: gru | iter: 20 | loss: 979.63 | apl: 2.43
building surrogate dataset...
training surrogate net... [10/12]
model: mlp | iter: 0 | loss: 26.74
model: mlp | iter: 250 | loss: 1.09
model: mlp | iter: 500 | loss: 0.87
model: mlp | iter: 750 | loss: 0.86
model: mlp | iter: 1000 | loss: 0.86
model: mlp | iter: 1250 | loss: 0.86
model: mlp | iter: 1500 | loss: 0.86
model: mlp | iter: 1750 | loss: 0.86
model: mlp | iter: 2000 | loss: 0.86
model: mlp | iter: 2250 | loss: 0.86
model: mlp | iter: 2500 | loss: 0.86
model: mlp | iter: 2750 | loss: 0.86
training deep net... [11/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 1772.54 | apl: 2.43
model: gru | iter: 10 | loss: 1193.10 | apl: 1.34
model: gru | iter: 20 | loss: 627.89 | apl: 1.34
building surrogate dataset...
training surrogate net... [11/12]
model: mlp | iter: 0 | loss: 24.46
model: mlp | iter: 250 | loss: 1.09
model: mlp | iter: 500 | loss: 1.04
model: mlp | iter: 750 | loss: 1.04
model: mlp | iter: 1000 | loss: 1.04
model: mlp | iter: 1250 | loss: 1.04
model: mlp | iter: 1500 | loss: 1.04
model: mlp | iter: 1750 | loss: 1.04
model: mlp | iter: 2000 | loss: 1.04
model: mlp | iter: 2250 | loss: 1.04
model: mlp | iter: 2500 | loss: 1.04
model: mlp | iter: 2750 | loss: 1.04
training deep net... [12/12], learning rate: 0.0100
model: gru | iter: 0 | loss: 874.39 | apl: 1.26
model: gru | iter: 10 | loss: 435.67 | apl: 1.26
model: gru | iter: 20 | loss: 242.64 | apl: 3.07
building surrogate dataset...
training surrogate net... [12/12]
model: mlp | iter: 0 | loss: 25.06
model: mlp | iter: 250 | loss: 1.08
model: mlp | iter: 500 | loss: 0.95
model: mlp | iter: 750 | loss: 0.95
model: mlp | iter: 1000 | loss: 0.95
model: mlp | iter: 1250 | loss: 0.95
model: mlp | iter: 1500 | loss: 0.95
model: mlp | iter: 1750 | loss: 0.95
model: mlp | iter: 2000 | loss: 0.95
model: mlp | iter: 2250 | loss: 0.95
model: mlp | iter: 2500 | loss: 0.95
model: mlp | iter: 2750 | loss: 0.95
saved trained model to ./trained_models
saved final decision tree to ./trained_models
